# üé¨ MLOps Final Assignment ‚Äî Movie Review Classification

This project is part of an MLOps final assignment focused on building, tuning, and deploying a sentiment classifier for movie reviews. It uses **NLP preprocessing**, **SVM** model tuning via **Optuna**, and tracks all artifacts via **MLflow**. A Flask API is served for prediction.

---

## üîß Features

- ‚úÖ Movie Review Classifier using Scikit-learn + SVM
- ‚úÖ Bayesian/Optuna-based hyperparameter tuning
- ‚úÖ Preprocessing with NLTK (stopwords, tokenization, lowercase, punctuation removal)
- ‚úÖ TF-IDF vectorization
- ‚úÖ MLflow integration for experiment tracking
- ‚úÖ Confusion Matrix & Top Feature logging
- ‚úÖ REST API using Flask
- ‚úÖ Docker-ready

---

## üìÅ Project Structure

```bash
.
‚îú‚îÄ‚îÄ aclImdb/                     # Dataset (IMDB reviews)
‚îÇ   ‚îî‚îÄ‚îÄ train/pos, train/neg     # Positive/Negative review .txt files
‚îú‚îÄ‚îÄ models/                      # Saved model & vectorizer
‚îÇ   ‚îú‚îÄ‚îÄ movies_review_classifier.pkl
‚îÇ   ‚îî‚îÄ‚îÄ tfidf_vectorizer.pkl
‚îú‚îÄ‚îÄ train.py                     # Training & MLflow logging
‚îú‚îÄ‚îÄ main.py                      # Flask API
‚îú‚îÄ‚îÄ common.py                    # Text preprocessing function
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îî‚îÄ‚îÄ README.md

-- CLone the Repository
git clone https://github.com/AbhiGTM19/Movie-Review-Sentiment-Classifier.git
cd mlops_finalassignment

-- Create Virtual Environment
python3 -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows

-- Install Dependencies
pip install -r requirements.txt

-- Download NLTK Resources (once)
python
>>> import nltk
>>> nltk.download('punkt')
>>> nltk.download('stopwords')
>>> exit()

-- Train the Model
python train.py

Artifacts logged:
Best parameters (C, kernel, gamma)
Accuracy and F1 score
Confusion matrix plot
Top TF-IDF features (if linear kernel)
Model: movies_review_classifier.pkl
Vectorizer: tfidf_vectorizer.pkl

--  Run the Flask API
flask run
Server will start at: http://127.0.0.1:5000

-- API Endpoints
1. GET /
Returns hyperparameters of trained model:
{
    "C": 10.55213024921588,
    "break_ties": false,
    "cache_size": 200,
    "class_weight": null,
    "coef0": 0.0,
    "decision_function_shape": "ovr",
    "degree": 3,
    "gamma": 0.9722301867133281,
    "kernel": "rbf",
    "max_iter": -1,
    "probability": true,
    "random_state": null,
    "shrinking": true,
    "tol": 0.001,
    "verbose": false
}

2. POST /predict
Input JSON:
{
  "review": "The movie was outstanding with powerful performances."
}

Response:
{
    "confidence": 0.9944,
    "prediction": "positive",
    "rating": "‚≠ê‚≠ê‚≠ê‚≠ê",
    "top_words": [
        "outstanding",
        "powerful",
        "performances",
        "movie"
    ],
    "verdict": "Recommended ‚úÖ"
}

-- View MLflow UI
mlflow ui
Visit: http://127.0.0.1:5000 for dashboard.

## Run with Docker (Online Method)

If you have Docker installed, pull and run directly from Docker Hub:

```bash
docker pull yugandhar0458/mlops_team10:latest
docker run -p 5000:5000 yugandhar0458/mlops_team10:latest


Authors
-- Abhishek Gautam
-- Model tuning by: Optuna
-- Deployment: Flask + Docker